_target_: src.models.spade_module.SPADEModule

name: SPADE

optimizer:
  _target_: torch.optim.Adam
  _partial_: true
  lr: 0.0002
  betas: [0.9, 0.99]
  weight_decay: 0

# scheduler:
#   _target_: torch.optim.lr_scheduler.MultiStepLR
#   _partial_: true
#   milestones: [250000, 300000]
#   gamma: 0.5

netG_A:
  _target_: src.models.components.networks_define.define_G
  netG_type: spade
  num_upsample_layers: 'normal'
  crop_size: 512
  aspect_ratio: 1.0
  ngf: 64
  use_vae: true
  z_dim: 256
  norm_G: 'spectralspadesyncbatch3x3'
  semantic_nc: 1 #64 # 1

netD_A:
  _target_: src.models.components.networks_define.define_D
  input_nc: 1
  ndf: 64
  # norm: 'instance'
  # n_layers_D: 3
  init_type: 'normal'

netE_A:
  _target_: src.models.components.networks_define.define_E
  netE_type: 'conv_encoder'
  ngf: 64
  norm_E: 'spectralinstance'
  crop_size: 512

params: # Other params
  lambda_ctx: 1 
  lambda_gan: 1 #0 # 0.1 
  lambda_kld: 0.05 
  lambda_l1: 1
  lambda_mind: 10
  reverse: ${data.reverse} # A->B if False, B->A if True
  use_split_inference: ${data.use_split_inference} # Inference for valid and test is divided into half from the original image (for memory issue)

  #Ablation
  ran_shift: null #null # "Put null or Interger" / random shift to ground truth when calculating Contextual Loss
